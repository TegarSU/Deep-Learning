{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import html\n",
    "import json\n",
    "import ast\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.id import Indonesian\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "nlp = Indonesian()  # use directly\n",
    "stopwords = spacy.lang.id.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Kelas-DeepLearning-Klasifikasi-master/all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values:\n",
      "\tdiposisi: 343\n",
      "\tjudul: 335\n",
      "\tkeluhan: 0\n",
      "\ttipe: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bantuan Langsung Sementara Masyarakat (BLSM)                                       11439\n",
       "BPJS Kesehatan                                                                      8323\n",
       "Topik Lainnya                                                                       7853\n",
       "Infrastruktur                                                                       6370\n",
       "Bantuan Siswa Miskin (BSM)                                                          5495\n",
       "Beras Miskin (Raskin)                                                               5012\n",
       "Kepegawaian                                                                         4709\n",
       "Kartu Indonesia Pintar (KIP)                                                        3907\n",
       "Permintaan Informasi Tentang Perubahan Data Peserta (Faskes Tk 1, Data peserta)     3712\n",
       "Perhubungan                                                                         3444\n",
       "Kepesertaan Non-KPS                                                                 3385\n",
       "Permintaan Informasi Tentang Besaran Iuran                                          3322\n",
       "Reformasi Birokrasi dan Tata Kelola                                                 3203\n",
       "Kesehatan                                                                           2933\n",
       "Permintaan Informasi Cek Pembayaran Iuran                                           2659\n",
       "Pelayanan Administrasi                                                              2520\n",
       "Permintaan Informasi Tentang Perubahan Jenis Kepesertaan                            2407\n",
       "Administrasi Kependudukan                                                           2382\n",
       "Permintaan Informasi Tentang Mekanisme Penonaktifan Peserta Meninggal               2343\n",
       "Data peserta tidak sesuai (Nama/TTL/NIK/Alamat/Faskes Tk.I)                         2311\n",
       "Pendidikan                                                                          2285\n",
       "Permintaan Informasi Tentang Pendaftaran PBPU dan BP Online                         2282\n",
       "Permintaan Informasi Pengecekan Status Kepesertaan                                  2053\n",
       "Lain-lain                                                                           2002\n",
       "Imigrasi                                                                            2001\n",
       "Name: tipe, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nNumber of missing values:')\n",
    "for col in data.columns:\n",
    "    print('\\t%s: %d' % (col, data[col].isnull().sum()))\n",
    "\n",
    "tipe = data[\"tipe\"].to_list()\n",
    "data[\"tipe\"].value_counts(dropna=False) #155 kelas diposisi, 37 kelas tipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PREPROCESSING\n",
    "\n",
    "# #Repeated Word\n",
    "# def repeated(token):\n",
    "#     repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "#     match = r'\\1\\2\\3'\n",
    "#     def replace(old_word):\n",
    "#         if old_word in bag:\n",
    "# #         ps = PorterStemmer()\n",
    "# #         ps.stem(old_word)\n",
    "# #         if wordnet.synsets(old_word):\n",
    "# #         if old_word in words.words():\n",
    "#             return old_word\n",
    "#         new_word = repeat_pattern.sub(match, old_word)\n",
    "#         return replace(new_word) if new_word != old_word else new_word\n",
    "    \n",
    "#     correct = [replace(word) for word in token]\n",
    "#     return correct   \n",
    "\n",
    "# #Akronim\n",
    "def slang(tokenized_sentence):\n",
    "    slang_word_dict = json.loads(open(\"slang_word_dict.txt\", 'r').read())\n",
    "#     print('tes')\n",
    "    for index in range(len(tokenized_sentence)):\n",
    "        for key, value in slang_word_dict.items():\n",
    "            for v in value:\n",
    "#                 print(tokenized_sentence[index],v)\n",
    "                if tokenized_sentence[index] == v:\n",
    "                    tokenized_sentence[index] = key\n",
    "                else:\n",
    "                    continue           \n",
    "    return \" \".join(tokenized_sentence)\n",
    "\n",
    "def stopword(teks):\n",
    "    clean = []\n",
    "    for i in teks:\n",
    "        if i not in stopwords:\n",
    "            clean.append(i)\n",
    "\n",
    "    return \" \".join(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    clean = text.lower() #lowercase\n",
    "    clean = html.unescape(clean) #html tag\n",
    "#     clean = re.sub(r\"rt @[\\w_]+:\", \" \", clean) #no RT\n",
    "#     clean = re.sub(\"@[A-Za-z0-9]+\", \"\", clean) #no Mention\n",
    "#     clean = re.sub(\"[0-9]\", \"\", clean) #no Number\n",
    "    clean = re.sub(r\"http\\S+\", \"\", clean) #no HTML\n",
    "#     clean = emoji.get_emoji_regexp().sub(\"\", clean) #EMOJI remover\n",
    "    clean = \" \".join(re.findall(\"[#a-zA-Z]{3,}\", clean)) #Puntc\n",
    "    clean = [token.text for token in nlp(clean)] #Token\n",
    "    #repeated\n",
    "    clean = slang(clean)#slang word\n",
    "    clean = [token.lemma_ for token in nlp(clean)] #Lemma\n",
    "    clean = stopword(clean) #Stopword\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean'] = data[\"keluhan\"].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()\n",
    "df = pd.DataFrame(data=data)\n",
    "df.to_csv(\"C:/xampp/htdocs/Deep-Learning/Kelas-DeepLearning-Klasifikasi-master/clean.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diposisi</th>\n",
       "      <th>judul</th>\n",
       "      <th>keluhan</th>\n",
       "      <th>tipe</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dinas Perumahan dan Kawasan Permukiman Kota Se...</td>\n",
       "      <td>Sebagian pju dijalan durian raya pedalangan ba...</td>\n",
       "      <td>Sebagian pju dijalan durian raya pedalangan ba...</td>\n",
       "      <td>Topik Lainnya</td>\n",
       "      <td>pju dijalan durian raya dalang banyumanik mati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kanwil Kementerian Hukum dan HAM Aceh</td>\n",
       "      <td>Mempertanyakan kelulusan SKD tapi tidak Capai ...</td>\n",
       "      <td>saya kecewa kelulusan SKD tak sesuai keputusan...</td>\n",
       "      <td>Kepegawaian</td>\n",
       "      <td>kecewa lulus skd suai putus menteri aceh capai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPJS Kesehatan KCU Medan</td>\n",
       "      <td>peralihan kepesertaan</td>\n",
       "      <td>0001125348254 Ingin beralih dari medan sehat k...</td>\n",
       "      <td>Permintaan Informasi Tentang Perubahan Jenis K...</td>\n",
       "      <td>alih medan sehat tanggung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direktorat Jenderal Imigrasi</td>\n",
       "      <td>Pelayanan Imigrasi Online Tidak Bisa Diakses</td>\n",
       "      <td>mau tanya untuk pelayanan imigrasi online suda...</td>\n",
       "      <td>Imigrasi</td>\n",
       "      <td>layan imigrasi online minggu diakses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BPJS Kesehatan KC Banda Aceh</td>\n",
       "      <td>Pindah layanan Kesehatan Tingkat Pertama</td>\n",
       "      <td>bagaiana proses untuk pindah puskesmas?</td>\n",
       "      <td>Permintaan Informasi Tentang Perubahan Data Pe...</td>\n",
       "      <td>bagaiana proses pindah puskesmas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            diposisi  \\\n",
       "0  Dinas Perumahan dan Kawasan Permukiman Kota Se...   \n",
       "1              Kanwil Kementerian Hukum dan HAM Aceh   \n",
       "2                           BPJS Kesehatan KCU Medan   \n",
       "3                       Direktorat Jenderal Imigrasi   \n",
       "4                       BPJS Kesehatan KC Banda Aceh   \n",
       "\n",
       "                                               judul  \\\n",
       "0  Sebagian pju dijalan durian raya pedalangan ba...   \n",
       "1  Mempertanyakan kelulusan SKD tapi tidak Capai ...   \n",
       "2                              peralihan kepesertaan   \n",
       "3       Pelayanan Imigrasi Online Tidak Bisa Diakses   \n",
       "4           Pindah layanan Kesehatan Tingkat Pertama   \n",
       "\n",
       "                                             keluhan  \\\n",
       "0  Sebagian pju dijalan durian raya pedalangan ba...   \n",
       "1  saya kecewa kelulusan SKD tak sesuai keputusan...   \n",
       "2  0001125348254 Ingin beralih dari medan sehat k...   \n",
       "3  mau tanya untuk pelayanan imigrasi online suda...   \n",
       "4            bagaiana proses untuk pindah puskesmas?   \n",
       "\n",
       "                                                tipe  \\\n",
       "0                                      Topik Lainnya   \n",
       "1                                        Kepegawaian   \n",
       "2  Permintaan Informasi Tentang Perubahan Jenis K...   \n",
       "3                                           Imigrasi   \n",
       "4  Permintaan Informasi Tentang Perubahan Data Pe...   \n",
       "\n",
       "                                               clean  \n",
       "0  pju dijalan durian raya dalang banyumanik mati...  \n",
       "1  kecewa lulus skd suai putus menteri aceh capai...  \n",
       "2                          alih medan sehat tanggung  \n",
       "3               layan imigrasi online minggu diakses  \n",
       "4                   bagaiana proses pindah puskesmas  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Kelas-DeepLearning-Klasifikasi-master/clean.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list()\n",
    "\n",
    "for i in data['clean']:\n",
    "    data = ast.literal_eval(i)\n",
    "    mylist.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('barat', 1), ('josenan', 1), ('kondisi', 1), ('lampu', 1), ('mati', 1), ('terang', 1), ('tilamupih', 1), ('titik', 1), ('wilayah', 1)]]\n",
      "\n",
      "\n",
      "barat 1\n",
      "josenan 1\n",
      "kondisi 1\n",
      "lampu 1\n",
      "mati 1\n",
      "terang 1\n",
      "tilamupih 1\n",
      "titik 1\n",
      "wilayah 1\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "dictionary = corpora.Dictionary(mylist)\n",
    "\n",
    "# Create Corpus\n",
    "texts = mylist\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [dictionary.doc2bow(text) for text in mylist]\n",
    "\n",
    "# View\n",
    "print([[(dictionary[id], freq) for id, freq in cp] for cp in corpus[:1]])\n",
    "print('\\n')\n",
    "for cp in corpus[:1]:\n",
    "    for id, freq in cp:\n",
    "        print(dictionary[id],freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "NUM_TOPICS = 10\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=NUM_TOPICS, \n",
    "                                           random_state=500,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=500,\n",
    "                                           passes=500,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.052*\"data\" + 0.051*\"raskin\" + 0.042*\"usaha\" + 0.029*\"ulang\" + 0.012*\"suai\" + 0.012*\"masyarakat\" + 0.010*\"indonesia\" + 0.009*\"kirim\" + 0.008*\"info\" + 0.007*\"coba\"')\n",
      "(1, '0.047*\"anak\" + 0.030*\"subsidi\" + 0.026*\"asi\" + 0.017*\"susu\" + 0.016*\"kerja\" + 0.013*\"bayi\" + 0.012*\"sulit\" + 0.012*\"makan\" + 0.011*\"susah\" + 0.010*\"khusus\"')\n",
      "(2, '0.116*\"kps\" + 0.092*\"blsm\" + 0.050*\"terima\" + 0.036*\"orang\" + 0.036*\"rt\" + 0.028*\"sasar\" + 0.024*\"rw\" + 0.021*\"miskin\" + 0.020*\"warga\" + 0.019*\"tolong\"')\n",
      "(3, '0.029*\"rp\" + 0.018*\"uang\" + 0.017*\"sekolah\" + 0.016*\"ribu\" + 0.015*\"biaya\" + 0.013*\"urus\" + 0.012*\"ambil\" + 0.012*\"surat\" + 0.012*\"tanggal\" + 0.012*\"guru\"')\n",
      "(4, '0.083*\"jakarta\" + 0.042*\"mohon\" + 0.041*\"jalan\" + 0.026*\"kasih\" + 0.022*\"hormat\" + 0.020*\"perintah\" + 0.017*\"tindak\" + 0.016*\"terima\" + 0.016*\"lapor\" + 0.016*\"terimakasih\"')\n",
      "(5, '0.027*\"bangun\" + 0.022*\"kendara\" + 0.018*\"utama\" + 0.013*\"siswa\" + 0.011*\"tepatnya\" + 0.011*\"akibat\" + 0.011*\"atur\" + 0.010*\"kjs\" + 0.010*\"tanjung\" + 0.010*\"perhatikan\"')\n",
      "(6, '0.092*\"rumah\" + 0.029*\"tangga\" + 0.026*\"kilogram\" + 0.023*\"sakit\" + 0.017*\"maaf\" + 0.014*\"sehat\" + 0.012*\"adakah\" + 0.010*\"puskesmas\" + 0.010*\"tegal\" + 0.010*\"askes\"')\n",
      "(7, '0.126*\"bbm\" + 0.031*\"spbu\" + 0.023*\"mobil\" + 0.022*\"motor\" + 0.016*\"beli\" + 0.015*\"jual\" + 0.013*\"isi\" + 0.012*\"premium\" + 0.011*\"menteri\" + 0.011*\"solar\"')\n",
      "(8, '0.121*\"desa\" + 0.061*\"kabupaten\" + 0.054*\"camat\" + 0.028*\"dana\" + 0.027*\"hak\" + 0.026*\"jawa\" + 0.010*\"blsm\" + 0.010*\"timur\" + 0.008*\"mhn\" + 0.007*\"potong\"')\n",
      "(9, '0.035*\"blt\" + 0.027*\"selamat\" + 0.019*\"siang\" + 0.017*\"ya\" + 0.014*\"bus\" + 0.012*\"tumpang\" + 0.012*\"halte\" + 0.012*\"sawah\" + 0.012*\"transjakarta\" + 0.011*\"jamkesmas\"')\n"
     ]
    }
   ],
   "source": [
    "topics = lda_model.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    \n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(61, 1), (65, 1), (202, 1), (249, 1), (1299, 1), (2692, 1)]\n",
      "[(0, 0.032714564), (1, 0.026944209), (2, 0.1645599), (3, 0.054821275), (4, 0.29437646), (5, 0.02891579), (6, 0.02618844), (7, 0.2865578), (8, 0.05479552), (9, 0.03012602)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = 'saya warga pademangan, harga bbm disini mahal sekali'\n",
    "new_doc = preprocessing(new_doc)\n",
    "sentence = nlp(new_doc)\n",
    "token_kata = [token.text for token in sentence]\n",
    "new_doc_bow = dictionary.doc2bow(token_kata )\n",
    "print(new_doc_bow)\n",
    "print(lda_model.get_document_topics(new_doc_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=mylist, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
